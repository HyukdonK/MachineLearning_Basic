{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "당뇨병.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRS6/MEV+q09SrmOm/m5rL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOISSYK/Machine-Learning-Basic/blob/main/%EB%8B%B9%EB%87%A8%EB%B3%91_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GohUyaZJ4qTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8CLNTs_4VI3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "diabetes=load_diabetes()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我导入了 load_diabetes() 模块，该模块从摆线学习加载糖尿病数据并将糖尿病数据加载到糖尿病中。 load_diabetes() 有 return_X_y(default: False) 和 as_frame(default: False) 作为参数。 他们每个人都会询问您是否只想加载数据以及是否要使用 Pandas 框架。 我将导入整个糖尿病对象，pandas 不会使用它，所以两个参数都加载了默认值（False）。"
      ],
      "metadata": {
        "id": "shxY7a3j6pZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "糖尿病是一个类似于 Python 字典的 Bunch 类。 Bunch 类可以使用点表示法访问类内的键。 糖尿病具有的键（属性）的类型如下。"
      ],
      "metadata": {
        "id": "khynWtKQ6zog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 数据 => ndarray 大小 (442,10)，输入值\n",
        "-目标的ndarray =>（442，），匹配\n",
        "- feature_names => 每列数据的特征名称\n",
        "- 框架 => (442,11) 旧数据（直到可调用）\n",
        "- DESCR => 数据集的描述\n",
        "- data_filename => 数据的位置路径\n",
        "- target_filename => 目标的位置路径\n",
        "- (data, target) => 输入值和元组（只能通过 returnX_y=True 访问）\n",
        "\n",
        "*ndarray : numpy 的链接"
      ],
      "metadata": {
        "id": "uI3pQhcW6zrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data=diabetes.data\n",
        "y_data=diabetes.target"
      ],
      "metadata": {
        "id": "I4RtnYdp4ZnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "首先，我们将获取数据和目标。"
      ],
      "metadata": {
        "id": "fAaVSRaZ7DZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LWENuSd6HLH",
        "outputId": "0123a417-6b3a-464e-c69f-5b2917c06ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "         0.01990842, -0.01764613],\n",
              "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "        -0.06832974, -0.09220405],\n",
              "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "         0.00286377, -0.02593034],\n",
              "       ...,\n",
              "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "        -0.04687948,  0.01549073],\n",
              "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "         0.04452837, -0.02593034],\n",
              "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "        -0.00421986,  0.00306441]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRYTRLRM6LL6",
        "outputId": "f3060b19-8eff-4a45-b5f3-9f2c9f53a8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "       220.,  57.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data.shape)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbd7D05i4Zo9",
        "outputId": "a1ef0a09-632a-477c-9d66-c909e958cd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(442,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "由于diabetes.data和diabetes.target都是ndarrays，所以可以使用shape来确定形状。\n"
      ],
      "metadata": {
        "id": "iWN_X0436oiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,feature_name in enumerate(diabetes.feature_names):\n",
        "  print(f'feature {i+1} : {feature_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVeZl0wP4Zq6",
        "outputId": "9cf924e9-9d9c-4bc7-f12e-ee76708cac57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature 1 : age\n",
            "feature 2 : sex\n",
            "feature 3 : bmi\n",
            "feature 4 : bp\n",
            "feature 5 : s1\n",
            "feature 6 : s2\n",
            "feature 7 : s3\n",
            "feature 8 : s4\n",
            "feature 9 : s5\n",
            "feature 10 : s6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正如我们在上面的解释中看到的，x 是一个 (442,10) 的数组，即一个总共有 442 个输入和 10 个信息的 ndarray。 因为有 442 个 x，所以肯定有 442 个 y。 在机器学习中，这些数据中包含的信息称为特征。 从现在开始，我将使用特质这个词。\n",
        "\n",
        "现在让我们来看看这10个特征中的每一个都是什么样的。"
      ],
      "metadata": {
        "id": "BVLsSwuq7R9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('<x_data[0]> : ',x_data[0])\n",
        "print()\n",
        "print('<y_data[0]> : ',y_data[0] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEIdZkpC4Zs8",
        "outputId": "fdb57684-7bfa-4745-b583-f6f0a8bea322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<x_data[0]> :  [ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
            " -0.04340085 -0.00259226  0.01990842 -0.01764613]\n",
            "\n",
            "<y_data[0]> :  151.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "第一个属性是年龄，第二个属性是性别，第三个属性是体脂指数……以此类推。 也就是说，可以看出442条数据分别记录了442名糖尿病患者的年龄、性别等。"
      ],
      "metadata": {
        "id": "ArZ9_ySb7Xkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLinear:\n",
        "  def __init__(self,learning_rate=0.001):\n",
        "    self.w=None #모델의 weight 벡터 self.w=(w_1,w_2)\n",
        "    self.b=None #모델의 bias\n",
        "    self.lr=learning_rate #모델의 학습률\n",
        "    self.losses=[] #매 에포크마다 손실을 저장하기 위한 리스트\n",
        "    self.weight_history=[] #매 에포크마다 계산된 weight를 저장하기 위한 리스트\n",
        "    self.bias_history=[] #매 에포크마다 계산된 bias를 저장하기 위한 리스트\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_pred=np.sum(x*self.w)+self.b #np.sum함수는 인자로 받은 numpy배열의 모든 원소의 합을 return합니다.\n",
        "    return y_pred\n",
        "\n",
        "  def loss(self,x,y):\n",
        "    y_pred=self.forward(x)\n",
        "    return (y_pred-y)**2\n",
        "\n",
        "  def gradient(self,x,y):\n",
        "    y_pred=self.forward(x)\n",
        "    w_grad=2*x*(y_pred-y)\n",
        "    b_grad=2*(y_pred-y)\n",
        "\n",
        "    return w_grad,b_grad\n",
        "\n",
        "  def fit(self,x_data,y_data,epochs=20):\n",
        "    self.w=np.ones(x_data.shape[1]) #모델의 weight들을 전부 1로 초기화\n",
        "    self.b=0 #모델의 bias를 0으로 초기화\n",
        "    for epoch in range(epochs):\n",
        "      l=0 #계산할 손실값\n",
        "      w_grad=np.zeros(x_data.shape[1]) #weight의 기울기를 누적할 numpy배열\n",
        "      b_grad=0  #bias의 기울기를 누적할 변수\n",
        "\n",
        "      for x,y in zip(x_data,y_data):\n",
        "        l+=self.loss(x,y)\n",
        "        w_i,b_i=self.gradient(x,y)\n",
        "\n",
        "        w_grad+=w_i #weight누적\n",
        "        b_grad+=b_i #bias누적\n",
        "\n",
        "      self.w-=self.lr*(w_grad/len(y_data)) #weight 업데이트\n",
        "      self.b-=self.lr*(b_grad/len(y_data)) #bias 업데이트\n",
        " \n",
        "      print(f'epoch ({epoch+1}) ===> loss : {l/len(y_data):.5f}')\n",
        "      self.losses.append(l/len(y_data)) #손실값 저장\n",
        "      self.weight_history.append(self.w) #weight 배열 저장\n",
        "      self.bias_history.append(self.b) #bias값 저장"
      ],
      "metadata": {
        "id": "XsYnE0iw4Zuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 fit 函数中初始化权重时，我稍微更改了代码。 由于我们可以通过 x.shape[1] 知道特征的数量，因此我们使用它来将 10 个权重初始化为 1。"
      ],
      "metadata": {
        "id": "VlSajOO_7d4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=MultiLinear(learning_rate=0.1)\n",
        "model.fit(x_data,y_data,epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU0FC9Hk4Zwm",
        "outputId": "d1dd3aa6-b80f-47e1-8d55-c2f77b2adca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch (1) ===> loss : 29055.28756\n",
            "epoch (2) ===> loss : 20715.48312\n",
            "epoch (3) ===> loss : 15375.24358\n",
            "epoch (4) ===> loss : 11954.73452\n",
            "epoch (5) ===> loss : 9762.86190\n",
            "epoch (6) ===> loss : 8357.32549\n",
            "epoch (7) ===> loss : 7455.05312\n",
            "epoch (8) ===> loss : 6874.87857\n",
            "epoch (9) ===> loss : 6500.85541\n",
            "epoch (10) ===> loss : 6258.77792\n",
            "epoch (11) ===> loss : 6101.15439\n",
            "epoch (12) ===> loss : 5997.59010\n",
            "epoch (13) ===> loss : 5928.63241\n",
            "epoch (14) ===> loss : 5881.83158\n",
            "epoch (15) ===> loss : 5849.21975\n",
            "epoch (16) ===> loss : 5825.69748\n",
            "epoch (17) ===> loss : 5808.00108\n",
            "epoch (18) ===> loss : 5794.04176\n",
            "epoch (19) ===> loss : 5782.48266\n",
            "epoch (20) ===> loss : 5772.46817\n",
            "epoch (21) ===> loss : 5763.45067\n",
            "epoch (22) ===> loss : 5755.07965\n",
            "epoch (23) ===> loss : 5747.13074\n",
            "epoch (24) ===> loss : 5739.46035\n",
            "epoch (25) ===> loss : 5731.97651\n",
            "epoch (26) ===> loss : 5724.62036\n",
            "epoch (27) ===> loss : 5717.35418\n",
            "epoch (28) ===> loss : 5710.15383\n",
            "epoch (29) ===> loss : 5703.00380\n",
            "epoch (30) ===> loss : 5695.89415\n",
            "epoch (31) ===> loss : 5688.81848\n",
            "epoch (32) ===> loss : 5681.77269\n",
            "epoch (33) ===> loss : 5674.75409\n",
            "epoch (34) ===> loss : 5667.76096\n",
            "epoch (35) ===> loss : 5660.79217\n",
            "epoch (36) ===> loss : 5653.84694\n",
            "epoch (37) ===> loss : 5646.92478\n",
            "epoch (38) ===> loss : 5640.02532\n",
            "epoch (39) ===> loss : 5633.14832\n",
            "epoch (40) ===> loss : 5626.29357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "虽然损失值出来有点大，但可以看出有一些收敛。 损失值大的原因是y值相比x值比较大（-0.2 <x <0.2, 25 <y <346）。"
      ],
      "metadata": {
        "id": "EwI4V8t97nwP"
      }
    }
  ]
}